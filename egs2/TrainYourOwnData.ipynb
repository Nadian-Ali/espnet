{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445de86b",
   "metadata": {},
   "source": [
    "<h1> This is template for training your own dataset text 2 speech </h1>\n",
    "<p style=\"color:blue\">read the data prepration notebook first</p>\n",
    "<h3> To Do </h3>\n",
    "add overview notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466421b",
   "metadata": {},
   "source": [
    "<p style = \"color:red\">Remove Project if You need to restart</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20a958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/espnet/egs2\n",
    "# !rm -rf Geeks #or the prjectName "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd53df",
   "metadata": {},
   "source": [
    "<h3> Move to the examples folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae1efb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/espnet/egs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c10f3",
   "metadata": {},
   "source": [
    "<h1> Clone template to new directory</h1>\n",
    "<p>for our case we copy the text to speech template into Geeks/tts1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06dba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_name=\"Geeks2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84f5ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geeks2\n",
      "2022-04-12T07:59:30 (setup.sh:71:main) Created: /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1//home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/tts1/cmd.sh /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1//home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/tts1/conf /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1//home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/tts1/local /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/tts1/tts.sh /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/tts1/path.sh /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/asr1/db.sh /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/asr1/scripts /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../TEMPLATE/asr1/pyscripts /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../../tools/kaldi/egs/wsj/s5/steps /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../../tools/kaldi/egs/wsj/s5/utils /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/../../../tools/kaldi/egs/sre08/v1/sid \n",
      "/home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "\n",
    "echo $1\n",
    "\n",
    "/home/ec2-user/SageMaker/espnet/egs2/TEMPLATE/tts1/setup.sh  /home/ec2-user/SageMaker/espnet/egs2/$1/tts1\n",
    "cd /home/ec2-user/SageMaker/espnet/egs2/$1/tts1\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b205",
   "metadata": {},
   "source": [
    "<h1> You have to  have your data prepared </h1>\n",
    "<p>For this task I have downloaded the data on my local and prepared data into the desired format and continues from there</p>\n",
    "\n",
    "<p style=\"color:blue\"> put detail about the dataprepration.py</p>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f56b80a",
   "metadata": {},
   "source": [
    "data should be formatted as \n",
    "\n",
    "\n",
    "|-- data\n",
    "|   |-- test\n",
    "|   |   |-- spk2utt  # Mapping a speaker-ID to a list of utterance-IDs\n",
    "|   |   |-- text     # Mapping a utterance-ID to a text\n",
    "|   |   |-- utt2spk  # Mappinng a utterance-ID to a speaker-ID\n",
    "|   |   `-- wav.scp  # Mappinng a utterance-ID to a path of audio file\n",
    "|   |-- train\n",
    "|   |   |-- spk2utt\n",
    "|   |   |-- text\n",
    "|   |   |-- utt2spk\n",
    "|   |   `-- wav.scp\n",
    "|   `-- valid\n",
    "|       |-- spk2utt\n",
    "|       |-- text\n",
    "|       |-- utt2spk\n",
    "|       `-- wav.scp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21b0ee",
   "metadata": {},
   "source": [
    "<h2> data prepration step is allready done on local </h2>\n",
    "to do: integrate into the project"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1563188",
   "metadata": {},
   "source": [
    "cd egs2/Geeks/tts1  # We always assume that our scripts are executed at this directory.\n",
    "\n",
    "# Assuming Stage1 creating `data`, so you can skip it if you have `data`.  \n",
    "./tts.sh \\\n",
    " --stage 2 \\\n",
    " --ngpu 1 \\\n",
    " --train_set train \\\n",
    " --valid_set valid \\\n",
    " --test_sets \"test\" \\  # you can add other things for test here e.g. \"test val\"\n",
    " \n",
    "# Use CUDA_VISIBLE_DEVICES to specify a gpu device id\n",
    "# If you meet CUDA out of memory error, change `batch_bins` ( or `batch_size`)\n",
    "\n",
    "\n",
    "train / val / test split is : 75% 20% 5%\n",
    "(we can condiered less data for validation as we dont have to worry much about overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93706b59",
   "metadata": {},
   "source": [
    "<h2>Importing data into project </h2>\n",
    "there are two folder to import \n",
    "<ul>\n",
    "    <li> wavs :this hole all the wave files</li>\n",
    "    <li> Data : this is a directory with the Kaldi style format*</li>\n",
    "</ul>\n",
    "<p>* Kaldi is another toolbox for speech processing and espnet is following that style</p>   \n",
    "\n",
    "\n",
    "Store your wav and data folders az zip file in you S3 bucket.\n",
    "and then move them into your working directory, in this case: /home/ec2-user/SageMaker/espnet/egs2/Geeks/tts1\n",
    "\n",
    "* don't forget to configure aws in your ec2-instance terminal using : aws configure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "238e9bec",
   "metadata": {},
   "source": [
    "#aws s3 cp source destination \n",
    "\n",
    "source data  : s3://commonvoicesdataset/data.zip\n",
    "source wavs  : s3://commonvoicesdataset/wavs.zip\n",
    "\n",
    "destination data: /home/ec2-user/SageMaker/espnet/egs2/Geeks/tts1\n",
    "destination wavs: /home/ec2-user/SageMaker/espnet/egs2/Geeks/tts1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "echo $1\n",
    "aws s3 cp  /home/ec2-user/SageMaker/espnet/egs2/$1/tts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "751f6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://commonvoicesdataset/data.zip to Geeks2/tts1/data.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "aws s3 cp s3://commonvoicesdataset/data.zip ge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148f30",
   "metadata": {},
   "source": [
    "<h3> Unzip and then remove the zip folder</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c0850",
   "metadata": {},
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6544d592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/data.zip\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "echo /home/ec2-user/SageMaker/espnet/egs2/$1/tts1/data.zip\n",
    "unzip -q /home/ec2-user/SageMaker/espnet/egs2/$1/tts1/data.zip -d /home/ec2-user/SageMaker/espnet/egs2/$1/tts1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5ba455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "unzip -q /home/ec2-user/SageMaker/espnet/egs2/$1/tts1/wavs.zip -d /home/ec2-user/SageMaker/espnet/egs2/$1/tts1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3593b85",
   "metadata": {},
   "source": [
    "<h3>Remove zip files if you want !</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm wavs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66a2c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7afbf291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$Project_name\"\n",
    "\n",
    "cd /home/ec2-user/SageMaker/espnet/egs2/$1/tts1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97baf8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d2bf8fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12T09:25:32 (tts.sh:211:main) ./tts.sh --stage 2 --ngpu 1 --train_set train --valid_set valid --test_sets test --stop-stage 2\n",
      "2022-04-12T09:25:32 (tts.sh:323:main) Stage 2: Format wav.scp: data/ -> dump/raw/\n",
      "utils/copy_data_dir.sh: copied data from data/train to dump/raw/org/train\n",
      "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
      "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
      "   for more information.\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory dump/raw/org/train\n",
      "2022-04-12T09:25:32 (format_wav_scp.sh:42:main) scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac --fs 16000 data/train/wav.scp dump/raw/org/train\n",
      "2022-04-12T09:25:32 (format_wav_scp.sh:110:main) [info]: without segments\n",
      "2022-04-12T09:28:17 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=165s]\n",
      "utils/copy_data_dir.sh: copied data from data/valid to dump/raw/org/valid\n",
      "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
      "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
      "   for more information.\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory dump/raw/org/valid\n",
      "2022-04-12T09:28:17 (format_wav_scp.sh:42:main) scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac --fs 16000 data/valid/wav.scp dump/raw/org/valid\n",
      "2022-04-12T09:28:17 (format_wav_scp.sh:110:main) [info]: without segments\n",
      "2022-04-12T09:29:15 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=58s]\n",
      "utils/copy_data_dir.sh: copied data from data/test to dump/raw/test\n",
      "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
      "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
      "   for more information.\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory dump/raw/test\n",
      "2022-04-12T09:29:15 (format_wav_scp.sh:42:main) scripts/audio/format_wav_scp.sh --nj 32 --cmd run.pl --audio-format flac --fs 16000 data/test/wav.scp dump/raw/test\n",
      "2022-04-12T09:29:15 (format_wav_scp.sh:110:main) [info]: without segments\n",
      "2022-04-12T09:29:44 (format_wav_scp.sh:142:main) Successfully finished. [elapsed=29s]\n",
      "2022-04-12T09:29:44 (tts.sh:1182:main) Skip the uploading stage\n",
      "2022-04-12T09:29:44 (tts.sh:1234:main) Skip the uploading to HuggingFace stage\n",
      "2022-04-12T09:29:44 (tts.sh:1237:main) Successfully finished. [elapsed=252s]\n"
     ]
    }
   ],
   "source": [
    "ge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb98f8",
   "metadata": {},
   "source": [
    "<hr style=\"width:50%;text-align:left;margin-left:0\">\n",
    "<p style =\"color:red\">\n",
    "*For a new recipie  modify tts.sh </p>\n",
    "\n",
    "train_set=\"train\"     # Name of training set.\n",
    "valid_set=\"valid\"     # Name of validation set used for monitoring/tuning network training.\n",
    "test_sets=\"test\"     # Names of test sets. Multiple items (e.g., both dev and eval sets) can be specified.\n",
    "\n",
    "look in : lines 105 106 107\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aa00ae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12T09:30:53 (tts.sh:211:main) ./tts.sh --stage 3 --stop-stage 3\n",
      "2022-04-12T09:30:53 (tts.sh:468:main) Stage 3: Remove long/short data: dump/raw/org -> dump/raw\n",
      "train\n",
      "utils/copy_data_dir.sh: copied data from dump/raw/org/train to dump/raw/train\n",
      "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
      "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
      "   for more information.\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory dump/raw/train\n",
      "this step was done\n",
      "fix_data_dir.sh: kept all 2149 utterances.\n",
      "fix_data_dir.sh: old files are kept in dump/raw/train/.backup\n",
      "train\n",
      "utils/copy_data_dir.sh: copied data from dump/raw/org/valid to dump/raw/valid\n",
      "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
      "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
      "   for more information.\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory dump/raw/valid\n",
      "this step was done\n",
      "fix_data_dir.sh: kept all 573 utterances.\n",
      "fix_data_dir.sh: old files are kept in dump/raw/valid/.backup\n",
      "2022-04-12T09:30:54 (tts.sh:1182:main) Skip the uploading stage\n",
      "2022-04-12T09:30:54 (tts.sh:1234:main) Skip the uploading to HuggingFace stage\n",
      "2022-04-12T09:30:54 (tts.sh:1237:main) Successfully finished. [elapsed=1s]\n"
     ]
    }
   ],
   "source": [
    "!./tts.sh --stage 3 --stop-stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e7b36185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12T09:30:59 (tts.sh:211:main) ./tts.sh --stage 4 --stop-stage 4 --srctexts data/train/text\n",
      "2022-04-12T09:31:00 (tts.sh:525:main) Stage 4: Generate token_list from data/train/text\n",
      "/home/ec2-user/anaconda3/envs/espnet/bin/python3 /home/ec2-user/SageMaker/espnet/espnet2/bin/tokenize_text.py --token_type phn -f 2- --input dump/raw/srctexts --output dump/token_list/phn_tacotron_g2p_en/tokens.txt --non_linguistic_symbols none --cleaner tacotron --g2p g2p_en --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'\n",
      "2022-04-12 09:31:29,985 (tokenize_text:174) INFO: OOV rate = 0.0 %\n",
      "2022-04-12T09:31:30 (tts.sh:1182:main) Skip the uploading stage\n",
      "2022-04-12T09:31:30 (tts.sh:1234:main) Skip the uploading to HuggingFace stage\n",
      "2022-04-12T09:31:30 (tts.sh:1237:main) Successfully finished. [elapsed=31s]\n"
     ]
    }
   ],
   "source": [
    "!./tts.sh --stage 4 --stop-stage 4 --srctexts \"data/train/text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4970ed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12T09:32:02 (tts.sh:211:main) ./tts.sh --stage 5 --stop-stage 5\n",
      "2022-04-12T09:32:02 (tts.sh:557:main) Stage 5: TTS collect stats: train_set=dump/raw/train, valid_set=dump/raw/valid\n",
      "2022-04-12T09:32:02 (tts.sh:644:main) Generate 'exp/tts_stats_raw_phn_tacotron_g2p_en/run.sh'. You can resume the process from stage 5 using this script\n",
      "2022-04-12T09:32:02 (tts.sh:648:main) TTS collect_stats started... log: 'exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.*.log'\n",
      "/home/ec2-user/anaconda3/envs/espnet/bin/python3 /home/ec2-user/SageMaker/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.1 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.2 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.3 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.4 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.5 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.6 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.7 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.8 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.9 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.10 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.11 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.12 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.13 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.14 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.15 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.16 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.17 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.18 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.19 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.20 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.21 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.22 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.23 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.24 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.25 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.26 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.27 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.28 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.29 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.30 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.31 --input_dir exp/tts_stats_raw_phn_tacotron_g2p_en/logdir/stats.32 --output_dir exp/tts_stats_raw_phn_tacotron_g2p_en\n",
      "2022-04-12T09:33:24 (tts.sh:1182:main) Skip the uploading stage\n",
      "2022-04-12T09:33:24 (tts.sh:1234:main) Skip the uploading to HuggingFace stage\n",
      "2022-04-12T09:33:24 (tts.sh:1237:main) Successfully finished. [elapsed=82s]\n"
     ]
    }
   ],
   "source": [
    "!./tts.sh --stage 5 --stop-stage 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4bbd87",
   "metadata": {},
   "source": [
    "<h1> Training starts here </h1>\n",
    "<br>\n",
    "<h2>1-  training stage </h2>\n",
    "<h3 style=\"color:blue\">Resutsl are stored in exp/tts_train_raw_phn_tacotron_g2p_en/train.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp [OPTION] SOURCE DEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1031683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /home/ec2-user/SageMaker/espnet/egs2/ljspeech/tts1/conf /home/ec2-user/SageMaker/espnet/egs2/Geeks2/tts1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894e13cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet/egs2/Geeks/tts1\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/ec2-user/SageMaker/espnet/egs2/Geeks/tts1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d09047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12T12:21:11 (tts.sh:210:main) ./tts.sh --stage 6 --stop-stage 6\n",
      "2022-04-12T12:21:12 (tts.sh:692:main) Stage 6: TTS Training: train_set=dump/raw/train, valid_set=dump/raw/valid\n",
      "2022-04-12T12:21:12 (tts.sh:872:main) Generate 'exp/tts_train_raw_phn_tacotron_g2p_en/run.sh'. You can resume the process from stage 6 using this script\n",
      "2022-04-12T12:21:12 (tts.sh:877:main) TTS training started... log: 'exp/tts_train_raw_phn_tacotron_g2p_en/train.log'\n",
      "2022-04-12 12:21:12,556 (launch:95) INFO: /home/ec2-user/anaconda3/envs/espnet/bin/python3 /home/ec2-user/SageMaker/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/tts_train_raw_phn_tacotron_g2p_en/train.log' --log exp/tts_train_raw_phn_tacotron_g2p_en/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/tts_train_raw_phn_tacotron_g2p_en/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.tts_train ' '\n",
      "2022-04-12 12:21:12,581 (launch:349) INFO: log file: exp/tts_train_raw_phn_tacotron_g2p_en/train.log\n",
      "run.pl: job failed, log is in exp/tts_train_raw_phn_tacotron_g2p_en/train.log\n",
      "Command '['run.pl', '--name', 'exp/tts_train_raw_phn_tacotron_g2p_en/train.log', '--gpu', '1', 'exp/tts_train_raw_phn_tacotron_g2p_en/train.log', 'python3', '-m', 'espnet2.bin.tts_train', ' ', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/espnet/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ec2-user/anaconda3/envs/espnet/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ec2-user/SageMaker/espnet/espnet2/bin/launch.py\", line 385, in <module>\n",
      "    main()\n",
      "  File \"/home/ec2-user/SageMaker/espnet/espnet2/bin/launch.py\", line 376, in main\n",
      "    raise RuntimeError(\n",
      "RuntimeError: \n",
      "################### The last 1000 lines of exp/tts_train_raw_phn_tacotron_g2p_en/train.log ###################\n",
      "# python3 -m espnet2.bin.tts_train \" \" --ngpu 1 --multiprocessing_distributed True \n",
      "# Started at Tue Apr 12 12:21:12 UTC 2022\n",
      "#\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package cmudict to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
      "/home/ec2-user/anaconda3/envs/espnet/bin/python3 /home/ec2-user/SageMaker/espnet/espnet2/bin/tts_train.py ' ' --ngpu 1 --multiprocessing_distributed True\n",
      "usage: tts_train.py [-h] [--config CONFIG] [--print_config]\n",
      "                    [--log_level {ERROR,WARNING,INFO,DEBUG,NOTSET}]\n",
      "                    [--dry_run DRY_RUN]\n",
      "                    [--iterator_type {sequence,chunk,task,none}]\n",
      "                    [--output_dir OUTPUT_DIR] [--ngpu NGPU] [--seed SEED]\n",
      "                    [--num_workers NUM_WORKERS] [--num_att_plot NUM_ATT_PLOT]\n",
      "                    [--dist_backend DIST_BACKEND]\n",
      "                    [--dist_init_method DIST_INIT_METHOD]\n",
      "                    [--dist_world_size DIST_WORLD_SIZE]\n",
      "                    [--dist_rank DIST_RANK] [--local_rank LOCAL_RANK]\n",
      "                    [--dist_master_addr DIST_MASTER_ADDR]\n",
      "                    [--dist_master_port DIST_MASTER_PORT]\n",
      "                    [--dist_launcher {slurm,mpi,None}]\n",
      "                    [--multiprocessing_distributed MULTIPROCESSING_DISTRIBUTED]\n",
      "                    [--unused_parameters UNUSED_PARAMETERS]\n",
      "                    [--sharded_ddp SHARDED_DDP]\n",
      "                    [--cudnn_enabled CUDNN_ENABLED]\n",
      "                    [--cudnn_benchmark CUDNN_BENCHMARK]\n",
      "                    [--cudnn_deterministic CUDNN_DETERMINISTIC]\n",
      "                    [--collect_stats COLLECT_STATS]\n",
      "                    [--write_collected_feats WRITE_COLLECTED_FEATS]\n",
      "                    [--max_epoch MAX_EPOCH] [--patience PATIENCE]\n",
      "                    [--val_scheduler_criterion VAL_SCHEDULER_CRITERION VAL_SCHEDULER_CRITERION]\n",
      "                    [--early_stopping_criterion EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION EARLY_STOPPING_CRITERION]\n",
      "                    [--best_model_criterion BEST_MODEL_CRITERION [BEST_MODEL_CRITERION ...]]\n",
      "                    [--keep_nbest_models KEEP_NBEST_MODELS [KEEP_NBEST_MODELS ...]]\n",
      "                    [--nbest_averaging_interval NBEST_AVERAGING_INTERVAL]\n",
      "                    [--grad_clip GRAD_CLIP] [--grad_clip_type GRAD_CLIP_TYPE]\n",
      "                    [--grad_noise GRAD_NOISE] [--accum_grad ACCUM_GRAD]\n",
      "                    [--no_forward_run NO_FORWARD_RUN] [--resume RESUME]\n",
      "                    [--train_dtype {float16,float32,float64}]\n",
      "                    [--use_amp USE_AMP] [--log_interval LOG_INTERVAL]\n",
      "                    [--use_matplotlib USE_MATPLOTLIB]\n",
      "                    [--use_tensorboard USE_TENSORBOARD]\n",
      "                    [--use_wandb USE_WANDB] [--wandb_project WANDB_PROJECT]\n",
      "                    [--wandb_id WANDB_ID] [--wandb_entity WANDB_ENTITY]\n",
      "                    [--wandb_name WANDB_NAME]\n",
      "                    [--wandb_model_log_interval WANDB_MODEL_LOG_INTERVAL]\n",
      "                    [--detect_anomaly DETECT_ANOMALY]\n",
      "                    [--pretrain_path PRETRAIN_PATH]\n",
      "                    [--init_param [INIT_PARAM [INIT_PARAM ...]]]\n",
      "                    [--ignore_init_mismatch IGNORE_INIT_MISMATCH]\n",
      "                    [--freeze_param [FREEZE_PARAM [FREEZE_PARAM ...]]]\n",
      "                    [--num_iters_per_epoch NUM_ITERS_PER_EPOCH]\n",
      "                    [--batch_size BATCH_SIZE]\n",
      "                    [--valid_batch_size VALID_BATCH_SIZE]\n",
      "                    [--batch_bins BATCH_BINS]\n",
      "                    [--valid_batch_bins VALID_BATCH_BINS]\n",
      "                    [--train_shape_file TRAIN_SHAPE_FILE]\n",
      "                    [--valid_shape_file VALID_SHAPE_FILE]\n",
      "                    [--batch_type {unsorted,sorted,folded,length,numel}]\n",
      "                    [--valid_batch_type {unsorted,sorted,folded,length,numel,None}]\n",
      "                    [--fold_length FOLD_LENGTH]\n",
      "                    [--sort_in_batch {descending,ascending}]\n",
      "                    [--sort_batch {descending,ascending}]\n",
      "                    [--multiple_iterator MULTIPLE_ITERATOR]\n",
      "                    [--chunk_length CHUNK_LENGTH]\n",
      "                    [--chunk_shift_ratio CHUNK_SHIFT_RATIO]\n",
      "                    [--num_cache_chunks NUM_CACHE_CHUNKS]\n",
      "                    [--train_data_path_and_name_and_type TRAIN_DATA_PATH_AND_NAME_AND_TYPE]\n",
      "                    [--valid_data_path_and_name_and_type VALID_DATA_PATH_AND_NAME_AND_TYPE]\n",
      "                    [--allow_variable_data_keys ALLOW_VARIABLE_DATA_KEYS]\n",
      "                    [--max_cache_size MAX_CACHE_SIZE]\n",
      "                    [--max_cache_fd MAX_CACHE_FD]\n",
      "                    [--valid_max_cache_size VALID_MAX_CACHE_SIZE]\n",
      "                    [--optim {adam,adamw,sgd,adadelta,adagrad,adamax,asgd,lbfgs,rmsprop,rprop,accagd,adabound,adamod,diffgrad,lamb,novograd,pid,qhm,sgdw,yogi}]\n",
      "                    [--optim_conf OPTIM_CONF]\n",
      "                    [--scheduler {reducelronplateau,lambdalr,steplr,multisteplr,exponentiallr,cosineannealinglr,noamlr,warmuplr,cycliclr,onecyclelr,cosineannealingwarmrestarts,None}]\n",
      "                    [--scheduler_conf SCHEDULER_CONF]\n",
      "                    [--token_list TOKEN_LIST] [--odim ODIM]\n",
      "                    [--model_conf MODEL_CONF]\n",
      "                    [--use_preprocessor USE_PREPROCESSOR]\n",
      "                    [--token_type {bpe,char,word,phn}] [--bpemodel BPEMODEL]\n",
      "                    [--non_linguistic_symbols NON_LINGUISTIC_SYMBOLS]\n",
      "                    [--cleaner {None,tacotron,jaconv,vietnamese,korean_cleaner}]\n",
      "                    [--g2p {None,g2p_en,g2p_en_no_space,pyopenjtalk,pyopenjtalk_kana,pyopenjtalk_accent,pyopenjtalk_accent_with_pause,pyopenjtalk_prosody,pypinyin_g2p,pypinyin_g2p_phone,espeak_ng_arabic,espeak_ng_german,espeak_ng_french,espeak_ng_spanish,espeak_ng_russian,espeak_ng_greek,espeak_ng_finnish,espeak_ng_hungarian,espeak_ng_dutch,espeak_ng_english_us_vits,espeak_ng_hindi,g2pk,g2pk_no_space,korean_jaso,korean_jaso_no_space}]\n",
      "                    [--feats_extract {fbank,spectrogram,linear_spectrogram}]\n",
      "                    [--feats_extract_conf FEATS_EXTRACT_CONF]\n",
      "                    [--normalize {global_mvn,None}]\n",
      "                    [--normalize_conf NORMALIZE_CONF]\n",
      "                    [--tts {tacotron2,transformer,fastspeech,fastspeech2,vits,joint_text2wav}]\n",
      "                    [--tts_conf TTS_CONF] [--pitch_extract {dio,None}]\n",
      "                    [--pitch_extract_conf PITCH_EXTRACT_CONF]\n",
      "                    [--pitch_normalize {global_mvn,None}]\n",
      "                    [--pitch_normalize_conf PITCH_NORMALIZE_CONF]\n",
      "                    [--energy_extract {energy,None}]\n",
      "                    [--energy_extract_conf ENERGY_EXTRACT_CONF]\n",
      "                    [--energy_normalize {global_mvn,None}]\n",
      "                    [--energy_normalize_conf ENERGY_NORMALIZE_CONF]\n",
      "tts_train.py: error: unrecognized arguments:  \n",
      "# Accounting: time=3 threads=1\n",
      "# Ended (code 2) at Tue Apr 12 12:21:15 UTC 2022, elapsed time 3 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./tts.sh --stage 6 --stop-stage 6 #--train_config conf/train.ymal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7cb59",
   "metadata": {},
   "source": [
    "<h3>1- Deconding stage</h3>\n",
    "\n",
    "this is how it goes : \n",
    "\n",
    "the model for TTS are stored in espent2.tts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aad9e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-06T18:38:00 (tts.sh:211:main) ./tts.sh --stage 7 --stop-stage 7\n",
      "2022-04-06T18:38:00 (tts.sh:935:main) Stage 7: Decoding: training_dir=exp/tts_train_raw_phn_tacotron_g2p_en\n",
      "2022-04-06T18:38:00 (tts.sh:958:main) Generate 'exp/tts_train_raw_phn_tacotron_g2p_en/inference_train.loss.ave/run.sh'. You can resume the process from stage 7 using this script\n",
      "2022-04-06T18:38:00 (tts.sh:1012:main) Decoding started... log: 'exp/tts_train_raw_phn_tacotron_g2p_en/inference_train.loss.ave/test/log/tts_inference.*.log'\n",
      "2022-04-06T18:41:52 (tts.sh:1182:main) Skip the uploading stage\n",
      "2022-04-06T18:41:52 (tts.sh:1234:main) Skip the uploading to HuggingFace stage\n",
      "2022-04-06T18:41:52 (tts.sh:1237:main) Successfully finished. [elapsed=232s]\n"
     ]
    }
   ],
   "source": [
    "!./tts.sh --stage 7 --stop-stage 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45fa6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798fc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4000f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/espnet\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ec2-user/SageMaker/espnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b494370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/espnet/espnet2/bin/tts_train.py\", line 2, in <module>\n",
      "    from espnet2.tasks.tts import TTSTask\n",
      "ModuleNotFoundError: No module named 'espnet2'\n"
     ]
    }
   ],
   "source": [
    "!python /home/ec2-user/SageMaker/espnet/espnet2/bin/tts_train.py --config CONFI--print_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_t2s",
   "language": "python",
   "name": "conda_t2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
